Model: BERTweet with LR=1e-05, Batch Size=16, Epochs=3, Warmup Steps=57
Accuracy: 85.29%
              precision    recall  f1-score   support

     Class 0       0.86      0.90      0.88       882
     Class 1       0.85      0.79      0.82       641

    accuracy                           0.85      1523
   macro avg       0.85      0.84      0.85      1523
weighted avg       0.85      0.85      0.85      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=16, Epochs=4, Warmup Steps=76
Accuracy: 83.72%
              precision    recall  f1-score   support

     Class 0       0.85      0.87      0.86       882
     Class 1       0.81      0.80      0.80       641

    accuracy                           0.84      1523
   macro avg       0.83      0.83      0.83      1523
weighted avg       0.84      0.84      0.84      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=16, Epochs=5, Warmup Steps=95
Accuracy: 81.75%
              precision    recall  f1-score   support

     Class 0       0.86      0.81      0.84       882
     Class 1       0.76      0.82      0.79       641

    accuracy                           0.82      1523
   macro avg       0.81      0.82      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=2e-05, Batch Size=16, Epochs=3, Warmup Steps=57
Accuracy: 81.88%
              precision    recall  f1-score   support

     Class 0       0.86      0.82      0.84       882
     Class 1       0.76      0.82      0.79       641

    accuracy                           0.82      1523
   macro avg       0.81      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=16, Epochs=4, Warmup Steps=76
Accuracy: 80.96%
              precision    recall  f1-score   support

     Class 0       0.86      0.81      0.83       882
     Class 1       0.75      0.81      0.78       641

    accuracy                           0.81      1523
   macro avg       0.80      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=16, Epochs=5, Warmup Steps=95
Accuracy: 81.55%
              precision    recall  f1-score   support

     Class 0       0.86      0.82      0.84       882
     Class 1       0.76      0.81      0.79       641

    accuracy                           0.82      1523
   macro avg       0.81      0.82      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=3e-05, Batch Size=16, Epochs=3, Warmup Steps=57
Accuracy: 80.37%
              precision    recall  f1-score   support

     Class 0       0.85      0.80      0.82       882
     Class 1       0.74      0.81      0.78       641

    accuracy                           0.80      1523
   macro avg       0.80      0.80      0.80      1523
weighted avg       0.81      0.80      0.80      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=16, Epochs=4, Warmup Steps=76
Accuracy: 78.99%
              precision    recall  f1-score   support

     Class 0       0.85      0.77      0.81       882
     Class 1       0.72      0.82      0.77       641

    accuracy                           0.79      1523
   macro avg       0.79      0.79      0.79      1523
weighted avg       0.80      0.79      0.79      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=16, Epochs=5, Warmup Steps=95
Accuracy: 81.68%
              precision    recall  f1-score   support

     Class 0       0.85      0.83      0.84       882
     Class 1       0.77      0.80      0.79       641

    accuracy                           0.82      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=1e-05, Batch Size=32, Epochs=3, Warmup Steps=28
Accuracy: 81.22%
              precision    recall  f1-score   support

     Class 0       0.84      0.83      0.84       882
     Class 1       0.77      0.79      0.78       641

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=32, Epochs=4, Warmup Steps=38
Accuracy: 81.68%
              precision    recall  f1-score   support

     Class 0       0.85      0.83      0.84       882
     Class 1       0.77      0.80      0.79       641

    accuracy                           0.82      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=32, Epochs=5, Warmup Steps=47
Accuracy: 82.21%
              precision    recall  f1-score   support

     Class 0       0.85      0.84      0.85       882
     Class 1       0.79      0.79      0.79       641

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=2e-05, Batch Size=32, Epochs=3, Warmup Steps=28
Accuracy: 82.47%
              precision    recall  f1-score   support

     Class 0       0.85      0.85      0.85       882
     Class 1       0.79      0.80      0.79       641

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=32, Epochs=4, Warmup Steps=38
Accuracy: 82.01%
              precision    recall  f1-score   support

     Class 0       0.85      0.84      0.84       882
     Class 1       0.78      0.79      0.79       641

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=32, Epochs=5, Warmup Steps=47
Accuracy: 82.01%
              precision    recall  f1-score   support

     Class 0       0.85      0.83      0.84       882
     Class 1       0.78      0.80      0.79       641

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=3e-05, Batch Size=32, Epochs=3, Warmup Steps=28
Accuracy: 82.01%
              precision    recall  f1-score   support

     Class 0       0.85      0.84      0.84       882
     Class 1       0.78      0.80      0.79       641

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=32, Epochs=4, Warmup Steps=38
Accuracy: 80.63%
              precision    recall  f1-score   support

     Class 0       0.86      0.79      0.83       882
     Class 1       0.74      0.83      0.78       641

    accuracy                           0.81      1523
   macro avg       0.80      0.81      0.80      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=32, Epochs=5, Warmup Steps=47
Accuracy: 81.22%
              precision    recall  f1-score   support

     Class 0       0.85      0.83      0.84       882
     Class 1       0.77      0.79      0.78       641

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=1e-05, Batch Size=64, Epochs=3, Warmup Steps=14
Accuracy: 81.88%
              precision    recall  f1-score   support

     Class 0       0.86      0.83      0.84       882
     Class 1       0.77      0.81      0.79       641

    accuracy                           0.82      1523
   macro avg       0.81      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=64, Epochs=4, Warmup Steps=19
Accuracy: 82.01%
              precision    recall  f1-score   support

     Class 0       0.84      0.85      0.85       882
     Class 1       0.79      0.78      0.78       641

    accuracy                           0.82      1523
   macro avg       0.82      0.81      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=64, Epochs=5, Warmup Steps=23
Accuracy: 81.75%
              precision    recall  f1-score   support

     Class 0       0.85      0.83      0.84       882
     Class 1       0.78      0.79      0.79       641

    accuracy                           0.82      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=2e-05, Batch Size=64, Epochs=3, Warmup Steps=14
Accuracy: 81.42%
              precision    recall  f1-score   support

     Class 0       0.85      0.82      0.84       882
     Class 1       0.77      0.80      0.78       641

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=64, Epochs=4, Warmup Steps=19
Accuracy: 81.88%
              precision    recall  f1-score   support

     Class 0       0.84      0.84      0.84       882
     Class 1       0.78      0.78      0.78       641

    accuracy                           0.82      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=64, Epochs=5, Warmup Steps=23
Accuracy: 81.94%
              precision    recall  f1-score   support

     Class 0       0.84      0.85      0.84       882
     Class 1       0.79      0.78      0.78       641

    accuracy                           0.82      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=3e-05, Batch Size=64, Epochs=3, Warmup Steps=14
Accuracy: 81.62%
              precision    recall  f1-score   support

     Class 0       0.84      0.84      0.84       882
     Class 1       0.78      0.78      0.78       641

    accuracy                           0.82      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=64, Epochs=4, Warmup Steps=19
Accuracy: 82.40%
              precision    recall  f1-score   support

     Class 0       0.84      0.86      0.85       882
     Class 1       0.80      0.78      0.79       641

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=64, Epochs=5, Warmup Steps=23
Accuracy: 82.07%
              precision    recall  f1-score   support

     Class 0       0.85      0.84      0.84       882
     Class 1       0.78      0.80      0.79       641

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
