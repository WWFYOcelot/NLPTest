Model: BERTweet with LR=1e-05, Batch Size=16, Epochs=3, Warmup Steps=57
Accuracy: 85.10%
              precision    recall  f1-score   support

     Class 0       0.85      0.90      0.87       865
     Class 1       0.85      0.79      0.82       658

    accuracy                           0.85      1523
   macro avg       0.85      0.84      0.85      1523
weighted avg       0.85      0.85      0.85      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=16, Epochs=4, Warmup Steps=76
Accuracy: 82.80%
              precision    recall  f1-score   support

     Class 0       0.84      0.86      0.85       865
     Class 1       0.81      0.79      0.80       658

    accuracy                           0.83      1523
   macro avg       0.83      0.82      0.82      1523
weighted avg       0.83      0.83      0.83      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=16, Epochs=5, Warmup Steps=95
Accuracy: 81.75%
              precision    recall  f1-score   support

     Class 0       0.84      0.83      0.84       865
     Class 1       0.79      0.79      0.79       658

    accuracy                           0.82      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=2e-05, Batch Size=16, Epochs=3, Warmup Steps=57
Accuracy: 81.68%
              precision    recall  f1-score   support

     Class 0       0.85      0.83      0.84       865
     Class 1       0.78      0.80      0.79       658

    accuracy                           0.82      1523
   macro avg       0.81      0.82      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=16, Epochs=4, Warmup Steps=76
Accuracy: 81.42%
              precision    recall  f1-score   support

     Class 0       0.85      0.82      0.83       865
     Class 1       0.78      0.80      0.79       658

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.82      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=16, Epochs=5, Warmup Steps=95
Accuracy: 80.96%
              precision    recall  f1-score   support

     Class 0       0.85      0.81      0.83       865
     Class 1       0.76      0.81      0.79       658

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=3e-05, Batch Size=16, Epochs=3, Warmup Steps=57
Accuracy: 81.35%
              precision    recall  f1-score   support

     Class 0       0.85      0.82      0.83       865
     Class 1       0.77      0.80      0.79       658

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=16, Epochs=4, Warmup Steps=76
Accuracy: 80.89%
              precision    recall  f1-score   support

     Class 0       0.85      0.81      0.83       865
     Class 1       0.76      0.81      0.78       658

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=16, Epochs=5, Warmup Steps=95
Accuracy: 81.55%
              precision    recall  f1-score   support

     Class 0       0.85      0.82      0.83       865
     Class 1       0.77      0.81      0.79       658

    accuracy                           0.82      1523
   macro avg       0.81      0.82      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=1e-05, Batch Size=32, Epochs=3, Warmup Steps=28
Accuracy: 81.94%
              precision    recall  f1-score   support

     Class 0       0.85      0.82      0.84       865
     Class 1       0.78      0.81      0.80       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=32, Epochs=4, Warmup Steps=38
Accuracy: 82.14%
              precision    recall  f1-score   support

     Class 0       0.86      0.83      0.84       865
     Class 1       0.78      0.82      0.80       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=32, Epochs=5, Warmup Steps=47
Accuracy: 81.68%
              precision    recall  f1-score   support

     Class 0       0.85      0.82      0.84       865
     Class 1       0.77      0.82      0.79       658

    accuracy                           0.82      1523
   macro avg       0.81      0.82      0.81      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=2e-05, Batch Size=32, Epochs=3, Warmup Steps=28
Accuracy: 80.24%
              precision    recall  f1-score   support

     Class 0       0.85      0.79      0.82       865
     Class 1       0.75      0.82      0.78       658

    accuracy                           0.80      1523
   macro avg       0.80      0.80      0.80      1523
weighted avg       0.81      0.80      0.80      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=32, Epochs=4, Warmup Steps=38
Accuracy: 82.73%
              precision    recall  f1-score   support

     Class 0       0.85      0.85      0.85       865
     Class 1       0.80      0.79      0.80       658

    accuracy                           0.83      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.83      0.83      0.83      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=32, Epochs=5, Warmup Steps=47
Accuracy: 80.56%
              precision    recall  f1-score   support

     Class 0       0.85      0.80      0.82       865
     Class 1       0.75      0.82      0.78       658

    accuracy                           0.81      1523
   macro avg       0.80      0.81      0.80      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=3e-05, Batch Size=32, Epochs=3, Warmup Steps=28
Accuracy: 82.40%
              precision    recall  f1-score   support

     Class 0       0.85      0.83      0.84       865
     Class 1       0.79      0.81      0.80       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.83      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=32, Epochs=4, Warmup Steps=38
Accuracy: 82.40%
              precision    recall  f1-score   support

     Class 0       0.84      0.86      0.85       865
     Class 1       0.81      0.78      0.79       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=32, Epochs=5, Warmup Steps=47
Accuracy: 80.89%
              precision    recall  f1-score   support

     Class 0       0.85      0.80      0.83       865
     Class 1       0.76      0.82      0.79       658

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=1e-05, Batch Size=64, Epochs=3, Warmup Steps=14
Accuracy: 82.27%
              precision    recall  f1-score   support

     Class 0       0.84      0.85      0.84       865
     Class 1       0.80      0.79      0.79       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=64, Epochs=4, Warmup Steps=19
Accuracy: 82.34%
              precision    recall  f1-score   support

     Class 0       0.85      0.84      0.84       865
     Class 1       0.79      0.80      0.80       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=1e-05, Batch Size=64, Epochs=5, Warmup Steps=23
Accuracy: 82.27%
              precision    recall  f1-score   support

     Class 0       0.84      0.85      0.84       865
     Class 1       0.80      0.79      0.79       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=2e-05, Batch Size=64, Epochs=3, Warmup Steps=14
Accuracy: 82.21%
              precision    recall  f1-score   support

     Class 0       0.84      0.84      0.84       865
     Class 1       0.79      0.79      0.79       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=64, Epochs=4, Warmup Steps=19
Accuracy: 83.26%
              precision    recall  f1-score   support

     Class 0       0.84      0.87      0.86       865
     Class 1       0.82      0.78      0.80       658

    accuracy                           0.83      1523
   macro avg       0.83      0.83      0.83      1523
weighted avg       0.83      0.83      0.83      1523

=================================================================
Model: BERTweet with LR=2e-05, Batch Size=64, Epochs=5, Warmup Steps=23
Accuracy: 82.60%
              precision    recall  f1-score   support

     Class 0       0.85      0.85      0.85       865
     Class 1       0.80      0.80      0.80       658

    accuracy                           0.83      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.83      0.83      0.83      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Model: BERTweet with LR=3e-05, Batch Size=64, Epochs=3, Warmup Steps=14
Accuracy: 82.01%
              precision    recall  f1-score   support

     Class 0       0.84      0.85      0.84       865
     Class 1       0.80      0.78      0.79       658

    accuracy                           0.82      1523
   macro avg       0.82      0.82      0.82      1523
weighted avg       0.82      0.82      0.82      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=64, Epochs=4, Warmup Steps=19
Accuracy: 81.35%
              precision    recall  f1-score   support

     Class 0       0.83      0.84      0.84       865
     Class 1       0.79      0.78      0.78       658

    accuracy                           0.81      1523
   macro avg       0.81      0.81      0.81      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================
Model: BERTweet with LR=3e-05, Batch Size=64, Epochs=5, Warmup Steps=23
Accuracy: 80.56%
              precision    recall  f1-score   support

     Class 0       0.85      0.79      0.82       865
     Class 1       0.75      0.82      0.78       658

    accuracy                           0.81      1523
   macro avg       0.80      0.81      0.80      1523
weighted avg       0.81      0.81      0.81      1523

=================================================================

|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
